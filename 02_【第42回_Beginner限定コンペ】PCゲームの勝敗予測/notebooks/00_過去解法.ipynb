{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# lightGBMのModelを構築\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X = train.drop(['gameId', 'blueWins'], axis=1)\n",
    "y = train['blueWins']\n",
    "\n",
    "test = test.drop('gameId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelのパラメーター\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'seed' : 71,\n",
    "    'verbose' : 0,\n",
    "    'metric' : 'binary-logloss'\n",
    "}\n",
    "\n",
    "# スコア、モデル保存用の配列\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# 訓練データをK-Foldにより4分割\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "\n",
    "# 学習を実施\n",
    "for tr_idx, va_idx in kf.split(X_train):\n",
    "  # 学習データ、評価データに分割\n",
    "  tr_x, va_x = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "  tr_y, va_y = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "  # lightGBMデータ構造に変換\n",
    "  lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "  lgb_eval = lgb.Dataset(va_x, va_y, reference=lgb_train)\n",
    "\n",
    "  model_gbm = lgb.train(\n",
    "      params,\n",
    "      lgb_train,\n",
    "      num_boost_round=500,\n",
    "      valid_sets=lgb_eval\n",
    "  )\n",
    "\n",
    "  # スコアの確認\n",
    "  pred_y = model_gbm.predict(va_x)\n",
    "  pred_y_label = np.where(pred_y>0.5, 1, 0)\n",
    "  score = accuracy_score(pred_y_label, va_y)\n",
    "\n",
    "  # 結果を格納\n",
    "  scores.append(score)\n",
    "  models.append(model_gbm)\n",
    "\n",
    "# 予測実行関数\n",
    "def pred(models, X_test):\n",
    "  # 予測結果サマリ\n",
    "  pred_y_summary = []\n",
    "\n",
    "  # model分ループ\n",
    "  for i in range(len(models)):\n",
    "    # 予測を実行\n",
    "    pred_y = models[i].predict(X_test)\n",
    "    # 結果を格納\n",
    "    pred_y_summary.append(pred_y)\n",
    "\n",
    "  # 各モデルの予測結果の平均値を作成\n",
    "  pred_y_mean = np.mean(pred_y_summary, axis=0)\n",
    "  return pred_y_mean\n",
    "\n",
    "# 予測を実行（Mean）\n",
    "pred_y = pred(models, test)\n",
    "pred_y_label = np.where(pred_y>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For early stopping, at least one dataset and eval metric is required for evaluation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [lgb\u001b[38;5;241m.\u001b[39mearly_stopping(\u001b[38;5;241m50\u001b[39m)]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# モデルのトレーニング\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model_gbm_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb_eval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# スコアの確認\u001b[39;00m\n\u001b[1;32m      8\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m model_gbm_tuned\u001b[38;5;241m.\u001b[39mpredict(va_x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:286\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_after_iter:\n\u001b[0;32m--> 286\u001b[0m         \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCallbackEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m                                \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbegin_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mend_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mevaluation_result_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_result_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mEarlyStopException \u001b[38;5;28;01mas\u001b[39;00m earlyStopException:\n\u001b[1;32m    293\u001b[0m     booster\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m=\u001b[39m earlyStopException\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:357\u001b[0m, in \u001b[0;36m_EarlyStoppingCallback.__call__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: CallbackEnv) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m==\u001b[39m env\u001b[38;5;241m.\u001b[39mbegin_iteration:\n\u001b[0;32m--> 357\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/callback.py:297\u001b[0m, in \u001b[0;36m_EarlyStoppingCallback._init\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\u001b[38;5;241m.\u001b[39mevaluation_result_list:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor early stopping, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    298\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least one dataset and eval metric is required for evaluation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopping_rounds \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopping_rounds should be greater than zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: For early stopping, at least one dataset and eval metric is required for evaluation"
     ]
    }
   ],
   "source": [
    "# 早期停止コールバックを設定\n",
    "callbacks = [lgb.early_stopping(50)]\n",
    "\n",
    "# モデルのトレーニング\n",
    "model_gbm_tuned = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=1000, callbacks=callbacks)\n",
    "\n",
    "# スコアの確認\n",
    "pred_y = model_gbm_tuned.predict(va_x)\n",
    "pred_y_label = np.where(pred_y > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression  Accuracy :  0.688125\n",
      "NearestNeighbors  Accuracy :  0.74625\n",
      "RandomForest  Accuracy :  0.740625\n",
      "DecisionTree  Accuracy :  0.708125\n",
      "AdaBoost  Accuracy :  0.76375\n",
      "NaiveBayes  Accuracy :  0.705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "names = ['LogisticRegression', 'NearestNeighbors', 'RandomForest', 'DecisionTree','AdaBoost', 'NaiveBayes']\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=123),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(random_state=123),\n",
    "    DecisionTreeClassifier(random_state=123),\n",
    "    AdaBoostClassifier(random_state=123),\n",
    "    GaussianNB()]\n",
    "\n",
    "for name, model in zip(names, classifiers):\n",
    "  model.fit(tr_x, tr_y)\n",
    "  pred_y = model.predict(va_x)\n",
    "  score = accuracy_score(pred_y, va_y)\n",
    "  print(name, ' Accuracy : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:59<00:00, 59.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# lightGBMのModelを構築\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチの条件設定\n",
    "grid = {RandomForestClassifier(random_state=123): {'n_estimators' : [i for i in range(1, 30)],\n",
    "                                                      'criterion' : ['gini', 'entropy'],\n",
    "                                                      'max_depth' : [i for i in range(1, 10)]}}\n",
    "\n",
    "# ベストスコア\n",
    "best_score = 0\n",
    "\n",
    "# 予測\n",
    "for model, param in tqdm(grid.items()):\n",
    "  # Model構築\n",
    "  clf = GridSearchCV(model, param)\n",
    "  clf.fit(tr_x, tr_y)\n",
    "  # スコアの確認\n",
    "  pred_y = clf.predict(va_x)\n",
    "  score = accuracy_score(pred_y, va_y)\n",
    "  # 判定\n",
    "  if best_score < score:\n",
    "    best_score = score\n",
    "    best_param = clf.best_params_\n",
    "    best_model = model.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'n_estimators': 19}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 25}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_param)\n",
    "\n",
    "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, X_test, mode):\n",
    "  # 結果格納用の配列\n",
    "  preds = []\n",
    "  preds_test = []\n",
    "  idxes = []\n",
    "  # クロスバリデーションで予測を実行\n",
    "  kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "  for tr_idx, va_idx in kf.split(X_train):\n",
    "    # 学習データ、評価データに分割\n",
    "    tr_x, va_x = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "    tr_y, va_y = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "    # modelを構築\n",
    "    if mode == 'LightGBM':\n",
    "      params = {'bagging_fraction': 0.4600347572555584,\n",
    "                'bagging_freq': 5,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'feature_fraction': 0.7,\n",
    "                'feature_pre_filter': False,\n",
    "                'lambda_l1': 0.004418000666138604,\n",
    "                'lambda_l2': 8.039538280454251e-06,\n",
    "                'min_child_samples': 20,\n",
    "                'num_leaves': 4,\n",
    "                'objective': 'binary',\n",
    "                'seed': 71,\n",
    "                'task': 'train',\n",
    "                'verbose': 0}\n",
    "      lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "      lgb_eval = lgb.Dataset(tr_x, tr_y, reference=lgb_train)\n",
    "      model = lgb.train(params, lgb_train, num_boost_round=1000, early_stopping_rounds=50, valid_sets=lgb_eval)\n",
    "    elif mode == 'RandomForest':\n",
    "      model = RandomForestClassifier(random_state=123, n_estimators=9, criterion='gini', max_depth=25)\n",
    "      model = model.fit(tr_x, tr_y)\n",
    "    elif mode == 'SVM':\n",
    "      model = svm.LinearSVC()\n",
    "      model = model.fit(tr_x, tr_y)\n",
    "    # 予測値を算出\n",
    "    pred = model.predict(va_x)\n",
    "    preds.append(pred)\n",
    "    pred_test = model.predict(X_test)\n",
    "    preds_test.append(pred_test)\n",
    "    idxes.append(idx)\n",
    "\n",
    "  # バリデーションデータに対する予測値を連結、その後元の順序に直す\n",
    "  idxes = np.concatenate(idxes)\n",
    "  preds = np.concatenate(preds, axis=0)\n",
    "  pred_train = preds[np.argsort(idxes)]\n",
    "\n",
    "  # テストデータに対する平均値を取得\n",
    "  preds_test = np.mean(preds_test, axis=0)\n",
    "  return pred_train, preds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
