{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBMのModelを構築\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X = train.drop(['gameId', 'blueWins'], axis=1)\n",
    "y = train['blueWins']\n",
    "\n",
    "test = test.drop('gameId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelのパラメーター\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'seed' : 71,\n",
    "    'verbose' : 0,\n",
    "    'metric' : 'binary-logloss'\n",
    "}\n",
    "\n",
    "# スコア、モデル保存用の配列\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "# 訓練データをK-Foldにより4分割\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "\n",
    "# 学習を実施\n",
    "for tr_idx, va_idx in kf.split(X_train):\n",
    "  # 学習データ、評価データに分割\n",
    "  tr_x, va_x = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "  tr_y, va_y = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "  # lightGBMデータ構造に変換\n",
    "  lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "  lgb_eval = lgb.Dataset(va_x, va_y, reference=lgb_train)\n",
    "\n",
    "  model_gbm = lgb.train(\n",
    "      params,\n",
    "      lgb_train,\n",
    "      num_boost_round=500,\n",
    "      valid_sets=lgb_eval\n",
    "  )\n",
    "\n",
    "  # スコアの確認\n",
    "  pred_y = model_gbm.predict(va_x)\n",
    "  pred_y_label = np.where(pred_y>0.5, 1, 0)\n",
    "  score = accuracy_score(pred_y_label, va_y)\n",
    "\n",
    "  # 結果を格納\n",
    "  scores.append(score)\n",
    "  models.append(model_gbm)\n",
    "\n",
    "# 予測実行関数\n",
    "def pred(models, X_test):\n",
    "  # 予測結果サマリ\n",
    "  pred_y_summary = []\n",
    "\n",
    "  # model分ループ\n",
    "  for i in range(len(models)):\n",
    "    # 予測を実行\n",
    "    pred_y = models[i].predict(X_test)\n",
    "    # 結果を格納\n",
    "    pred_y_summary.append(pred_y)\n",
    "\n",
    "  # 各モデルの予測結果の平均値を作成\n",
    "  pred_y_mean = np.mean(pred_y_summary, axis=0)\n",
    "  return pred_y_mean\n",
    "\n",
    "# 予測を実行（Mean）\n",
    "pred_y = pred(models, test)\n",
    "pred_y_label = np.where(pred_y>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# チューニングあり\n",
    "from optuna.integration import lightgbm as lgb\n",
    "\n",
    "model_gbm_tuned = lgb.train(param, lgb_train, valid_sets=lgb_eval, num_boost_round=1000, early_stopping_rounds=50)\n",
    "\n",
    "# スコアの確認\n",
    "pred_y = model_gbm_tuned.predict(va_x)\n",
    "pred_y_label = np.where(pred_y>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression  Accuracy :  0.688125\n",
      "NearestNeighbors  Accuracy :  0.745\n",
      "RandomForest  Accuracy :  0.740625\n",
      "DecisionTree  Accuracy :  0.708125\n",
      "AdaBoost  Accuracy :  0.76375\n",
      "NaiveBayes  Accuracy :  0.705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "names = ['LogisticRegression', 'NearestNeighbors', 'RandomForest', 'DecisionTree','AdaBoost', 'NaiveBayes']\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=123),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(random_state=123),\n",
    "    DecisionTreeClassifier(random_state=123),\n",
    "    AdaBoostClassifier(random_state=123),\n",
    "    GaussianNB()]\n",
    "\n",
    "for name, model in zip(names, classifiers):\n",
    "  model.fit(tr_x, tr_y)\n",
    "  pred_y = model.predict(va_x)\n",
    "  score = accuracy_score(pred_y, va_y)\n",
    "  print(name, ' Accuracy : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:28<00:00, 88.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# lightGBMのModelを構築\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチの条件設定\n",
    "grid = {RandomForestClassifier(random_state=123): {'n_estimators' : [i for i in range(1, 30)],\n",
    "                                                      'criterion' : ['gini', 'entropy'],\n",
    "                                                      'max_depth' : [i for i in range(1, 10)]}}\n",
    "\n",
    "# ベストスコア\n",
    "best_score = 0\n",
    "\n",
    "# 予測\n",
    "for model, param in tqdm(grid.items()):\n",
    "  # Model構築\n",
    "  clf = GridSearchCV(model, param)\n",
    "  clf.fit(tr_x, tr_y)\n",
    "  # スコアの確認\n",
    "  pred_y = clf.predict(va_x)\n",
    "  score = accuracy_score(pred_y, va_y)\n",
    "  # 判定\n",
    "  if best_score < score:\n",
    "    best_score = score\n",
    "    best_param = clf.best_params_\n",
    "    best_model = model.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'n_estimators': 19}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 25}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_param)\n",
    "\n",
    "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, X_test, mode):\n",
    "  # 結果格納用の配列\n",
    "  preds = []\n",
    "  preds_test = []\n",
    "  idxes = []\n",
    "  # クロスバリデーションで予測を実行\n",
    "  kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "  for tr_idx, va_idx in kf.split(X_train):\n",
    "    # 学習データ、評価データに分割\n",
    "    tr_x, va_x = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "    tr_y, va_y = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "    # modelを構築\n",
    "    if mode == 'LightGBM':\n",
    "      params = {'bagging_fraction': 0.4600347572555584,\n",
    "                'bagging_freq': 5,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'feature_fraction': 0.7,\n",
    "                'feature_pre_filter': False,\n",
    "                'lambda_l1': 0.004418000666138604,\n",
    "                'lambda_l2': 8.039538280454251e-06,\n",
    "                'min_child_samples': 20,\n",
    "                'num_leaves': 4,\n",
    "                'objective': 'binary',\n",
    "                'seed': 71,\n",
    "                'task': 'train',\n",
    "                'verbose': 0}\n",
    "      lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "      lgb_eval = lgb.Dataset(tr_x, tr_y, reference=lgb_train)\n",
    "      model = lgb.train(params, lgb_train, num_boost_round=1000, early_stopping_rounds=50, valid_sets=lgb_eval)\n",
    "    elif mode == 'RandomForest':\n",
    "      model = RandomForestClassifier(random_state=123, n_estimators=9, criterion='gini', max_depth=25)\n",
    "      model = model.fit(tr_x, tr_y)\n",
    "    elif mode == 'SVM':\n",
    "      model = svm.LinearSVC()\n",
    "      model = model.fit(tr_x, tr_y)\n",
    "    # 予測値を算出\n",
    "    pred = model.predict(va_x)\n",
    "    preds.append(pred)\n",
    "    pred_test = model.predict(X_test)\n",
    "    preds_test.append(pred_test)\n",
    "    idxes.append(idx)\n",
    "\n",
    "  # バリデーションデータに対する予測値を連結、その後元の順序に直す\n",
    "  idxes = np.concatenate(idxes)\n",
    "  preds = np.concatenate(preds, axis=0)\n",
    "  pred_train = preds[np.argsort(idxes)]\n",
    "\n",
    "  # テストデータに対する平均値を取得\n",
    "  preds_test = np.mean(preds_test, axis=0)\n",
    "  return pred_train, preds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
